{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhUzrrIvyIHW",
        "outputId": "74d2cda5-2b0b-41fe-a065-12a11d337232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "import base64\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PHG5Ta7roJyY"
      },
      "outputs": [],
      "source": [
        "with open('scrapedTextNoImagesTwo.txt', 'r') as file:\n",
        "  text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jAWKeTOkM4w7"
      },
      "outputs": [],
      "source": [
        "pages = text.split(\"\\u3019\")\n",
        "# Removes the initial unicode character used to denote the start of a page\n",
        "pages = [x[1:] for x in pages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_M7ly2Mymqsd"
      },
      "outputs": [],
      "source": [
        "prompt = '''\n",
        "I am training a large language model (LLM) using information from a wiki.\n",
        "My goal is to evaluate the model's comprehension, factual recall, and reasoning\n",
        "abilities by generating a set of specific, detailed questions to test it.\n",
        "\n",
        "Please avoid vague, broad, or generic questions such as 'What does this text say' or\n",
        "other general questions that assume broader context. Focus on generating\n",
        "specific, detailed, and meaningful questions based only on the information\n",
        "provided in the text. The questions should not assume knowledge outside of the provided\n",
        "text, nor reference 'this page', 'this section,' 'this text', or other location-based language.\n",
        "\n",
        "Treat the text as a standalone passage, and generate factual, inferential, or conceptual\n",
        "questions that can be answered **directly** from the content provided. Avoid\n",
        "hallucinations and ensure that the questions target specific elements from the text.\n",
        "\n",
        "Please return a JSON object with the following keys:\n",
        "1. Keyname: \"url\". Contains a URL that is found at the beginning of the text I provide for you.\n",
        "2. Keyname: \"Q/A\". A Q/A array where each array element is another object in JSON notation\n",
        "containing a 'question' key that holds a specific, detail-focused question and an 'answer' key\n",
        "containing the correct answer from the provided text.\n",
        "3. A 'total' key that lists the total number of questions.\n",
        "\n",
        "Make sure to use double quotes everywhere, unless you're writing a quote\n",
        "within a double quote, in which case you can use single quotes.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ur1Mm_8OuN1-"
      },
      "outputs": [],
      "source": [
        "def questionGeneration(page):\n",
        "    headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {userdata.get('OPEN_API_KEY')}\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "      \"model\": \"gpt-4o-mini\",\n",
        "      \"messages\": [\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "            {\n",
        "              \"type\": \"text\",\n",
        "              \"text\": f\"{prompt}. Now here is wiki page: {page}\"\n",
        "            },\n",
        "          ]\n",
        "        }\n",
        "      ],\n",
        "      \"max_tokens\": 3000\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "\n",
        "    # Prints the response, then reformat's GPTs json string\n",
        "    print(response.json()['choices'][0]['message']['content'])\n",
        "    return response.json()['choices'][0]['message']['content'].replace(\"\\n\", \"\")[7:-3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B4J-tV3Pcqe",
        "outputId": "6e940c5a-3456-47cb-a638-2ca9ddff44fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating questions about page 0\n"
          ]
        }
      ],
      "source": [
        "with open('questionsList.json', 'a') as file:\n",
        "    file.write(\"[\")\n",
        "for i in range(len(pages)):\n",
        "  print(f\"Generating questions about page {i}\")\n",
        "  ans = {}\n",
        "  for j in range(3):\n",
        "    try:\n",
        "        ans = json.loads(questionGeneration(pages[i]))\n",
        "        break\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "  with open('questionsList.json', 'a') as file:\n",
        "    json.dump(ans, file, ensure_ascii=False, indent=4)\n",
        "    file.write(\",\")\n",
        "with open('questionsList.json', 'a') as file:\n",
        "  file.write(\"]\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}