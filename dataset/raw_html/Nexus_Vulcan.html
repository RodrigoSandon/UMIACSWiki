<!DOCTYPE html>
<html class="client-nojs" dir="ltr" lang="en">
 <head>
  <meta charset="utf-8"/>
  <title>
   Nexus/Vulcan - UMIACS
  </title>
  <script>
   document.documentElement.className="client-js";RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"Zv3GoCvmTZe3NoESbiKlmgAAAAI","wgCSPNonce":false,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Nexus/Vulcan","wgTitle":"Nexus/Vulcan","wgCurRevisionId":12037,"wgRevisionId":12037,"wgArticleId":3221,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":[],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Nexus/Vulcan","wgRelevantArticleId":3221,"wgIsProbablyEditable":false,"wgRelevantPageIsProbablyEditable":false,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgVector2022PreviewPages":[]};RLSTATE={"site.styles":"ready","user.styles":
"ready","user":"ready","user.options":"loading","skins.vector.styles.legacy":"ready"};RLPAGEMODULES=["site","mediawiki.page.ready","mediawiki.toc","skins.vector.legacy.js"];
  </script>
  <script>
   (RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});});});
  </script>
  <link href="/umiacs/load.php?lang=en&amp;modules=skins.vector.styles.legacy&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
  <script async="" src="/umiacs/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector">
  </script>
  <meta content="" name="ResourceLoaderDynamicStyles"/>
  <link href="/umiacs/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
  <meta content="MediaWiki 1.39.7" name="generator"/>
  <meta content="telephone=no" name="format-detection"/>
  <meta content="width=1000" name="viewport"/>
  <link href="/favicon.ico" rel="icon"/>
  <link href="/umiacs/opensearch_desc.php" rel="search" title="UMIACS (en)" type="application/opensearchdescription+xml"/>
  <link href="https://wiki.umiacs.umd.edu/umiacs/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>
  <link href="/umiacs/index.php?title=Special:RecentChanges&amp;feed=atom" rel="alternate" title="UMIACS Atom feed" type="application/atom+xml"/>
 </head>
 <body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-Nexus_Vulcan rootpage-Nexus_Vulcan skin-vector action-view skin-vector-legacy vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-language-alert-in-sidebar-disabled vector-feature-sticky-header-disabled vector-feature-sticky-header-edit-disabled vector-feature-table-of-contents-disabled vector-feature-visual-enhancement-next-disabled">
  <div class="noprint" id="mw-page-base">
  </div>
  <div class="noprint" id="mw-head-base">
  </div>
  <div class="mw-body" id="content" role="main">
   <a id="top">
   </a>
   <div id="siteNotice">
   </div>
   <div class="mw-indicators">
   </div>
   <h1 class="firstHeading mw-first-heading" id="firstHeading">
    <span class="mw-page-title-main">
     Nexus/Vulcan
    </span>
   </h1>
   <div class="vector-body" id="bodyContent">
    <div class="noprint" id="siteSub">
     From UMIACS
    </div>
    <div id="contentSub">
    </div>
    <div id="contentSub2">
    </div>
    <div id="jump-to-nav">
    </div>
    <a class="mw-jump-link" href="#mw-head">
     Jump to navigation
    </a>
    <a class="mw-jump-link" href="#searchInput">
     Jump to search
    </a>
    <div class="mw-body-content mw-content-ltr" dir="ltr" id="mw-content-text" lang="en">
     <div class="mw-parser-output">
      <p>
       The compute nodes from Vulcan's previous standalone cluster have folded into
       <a href="/umiacs/index.php/Nexus" title="Nexus">
        Nexus
       </a>
       as of the scheduled
       <a href="/umiacs/index.php/MonthlyMaintenanceWindow" title="MonthlyMaintenanceWindow">
        maintenance window
       </a>
       for August 2023 (Thursday 08/17/2023, 5-8pm).
      </p>
      <p>
       The Nexus cluster already has a large pool of compute resources made possible through college-level funding for UMIACS and CSD faculty. Details on common nodes already in the cluster (Tron partition) can be found
       <a href="/umiacs/index.php/Nexus/Tron" title="Nexus/Tron">
        here
       </a>
       .
      </p>
      <p>
       Please
       <a href="/umiacs/index.php/HelpDesk" title="HelpDesk">
        contact staff
       </a>
       with any questions or concerns.
      </p>
      <div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation">
       <input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/>
       <div class="toctitle" dir="ltr" lang="en">
        <h2 id="mw-toc-heading">
         Contents
        </h2>
        <span class="toctogglespan">
         <label class="toctogglelabel" for="toctogglecheckbox">
         </label>
        </span>
       </div>
       <ul>
        <li class="toclevel-1 tocsection-1">
         <a href="#Usage">
          <span class="tocnumber">
           1
          </span>
          <span class="toctext">
           Usage
          </span>
         </a>
        </li>
        <li class="toclevel-1 tocsection-2">
         <a href="#Nodes">
          <span class="tocnumber">
           2
          </span>
          <span class="toctext">
           Nodes
          </span>
         </a>
        </li>
        <li class="toclevel-1 tocsection-3">
         <a href="#Partitions">
          <span class="tocnumber">
           3
          </span>
          <span class="toctext">
           Partitions
          </span>
         </a>
        </li>
        <li class="toclevel-1 tocsection-4">
         <a href="#Accounts">
          <span class="tocnumber">
           4
          </span>
          <span class="toctext">
           Accounts
          </span>
         </a>
        </li>
        <li class="toclevel-1 tocsection-5">
         <a href="#QoS">
          <span class="tocnumber">
           5
          </span>
          <span class="toctext">
           QoS
          </span>
         </a>
        </li>
        <li class="toclevel-1 tocsection-6">
         <a href="#Storage">
          <span class="tocnumber">
           6
          </span>
          <span class="toctext">
           Storage
          </span>
         </a>
         <ul>
          <li class="toclevel-2 tocsection-7">
           <a href="#Home_Directories">
            <span class="tocnumber">
             6.1
            </span>
            <span class="toctext">
             Home Directories
            </span>
           </a>
          </li>
          <li class="toclevel-2 tocsection-8">
           <a href="#Scratch_Directories">
            <span class="tocnumber">
             6.2
            </span>
            <span class="toctext">
             Scratch Directories
            </span>
           </a>
           <ul>
            <li class="toclevel-3 tocsection-9">
             <a href="#Network_Scratch_Directory">
              <span class="tocnumber">
               6.2.1
              </span>
              <span class="toctext">
               Network Scratch Directory
              </span>
             </a>
            </li>
            <li class="toclevel-3 tocsection-10">
             <a href="#Local_Scratch_Directories">
              <span class="tocnumber">
               6.2.2
              </span>
              <span class="toctext">
               Local Scratch Directories
              </span>
             </a>
            </li>
           </ul>
          </li>
          <li class="toclevel-2 tocsection-11">
           <a href="#Datasets">
            <span class="tocnumber">
             6.3
            </span>
            <span class="toctext">
             Datasets
            </span>
           </a>
          </li>
          <li class="toclevel-2 tocsection-12">
           <a href="#Project_Storage">
            <span class="tocnumber">
             6.4
            </span>
            <span class="toctext">
             Project Storage
            </span>
           </a>
          </li>
          <li class="toclevel-2 tocsection-13">
           <a href="#Object_Storage">
            <span class="tocnumber">
             6.5
            </span>
            <span class="toctext">
             Object Storage
            </span>
           </a>
          </li>
         </ul>
        </li>
        <li class="toclevel-1 tocsection-14">
         <a href="#Migration">
          <span class="tocnumber">
           7
          </span>
          <span class="toctext">
           Migration
          </span>
         </a>
         <ul>
          <li class="toclevel-2 tocsection-15">
           <a href="#Home_Directories_2">
            <span class="tocnumber">
             7.1
            </span>
            <span class="toctext">
             Home Directories
            </span>
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </div>
      <h2>
       <span class="mw-headline" id="Usage">
        Usage
       </span>
      </h2>
      <p>
       You can
       <a class="mw-redirect" href="/umiacs/index.php/SSH" title="SSH">
        SSH
       </a>
       to
       <code>
        nexusvulcan.umiacs.umd.edu
       </code>
       to log in to a submission host.
      </p>
      <p>
       If you store something in a local directory (/tmp, /scratch0) on one of the two submission hosts, you will need to connect to that same submission host to access it later. The actual submission hosts are:
      </p>
      <ul>
       <li>
        <code>
         nexusvulcan00.umiacs.umd.edu
        </code>
       </li>
       <li>
        <code>
         nexusvulcan01.umiacs.umd.edu
        </code>
       </li>
      </ul>
      <p>
       All partitions, QoSes, and account names from the standalone Vulcan cluster have been moved over to Nexus. However, please note that
       <code>
        vulcan-
       </code>
       is prepended to all of the values that were present in the standalone Vulcan cluster to distinguish them from existing values in Nexus. The lone exception is the base account that was named
       <code>
        vulcan
       </code>
       in the standalone cluster (it is also named just
       <code>
        vulcan
       </code>
       in Nexus).
      </p>
      <p>
       Here are some before/after examples of job submission with various parameters:
      </p>
      <table class="wikitable">
       <tbody>
        <tr>
         <th>
          Standalone Vulcan cluster submission command
         </th>
         <th>
          Nexus cluster submission command
         </th>
        </tr>
        <tr>
         <td>
          <code>
           srun --partition=dpart --qos=medium --account=abhinav --gres=gpu:gtx1080ti:2 --pty bash
          </code>
         </td>
         <td>
          <code>
           srun --partition=vulcan-dpart --qos=vulcan-medium --account=vulcan-abhinav --gres=gpu:gtx1080ti:2 --pty bash
          </code>
         </td>
        </tr>
        <tr>
         <td>
          <code>
           srun --partition=cpu --qos=cpu --pty bash
          </code>
         </td>
         <td>
          <code>
           srun --partition=vulcan-cpu --qos=vulcan-cpu --account=vulcan --pty bash
          </code>
         </td>
        </tr>
        <tr>
         <td>
          <code>
           srun --partition=scavenger --qos=scavenger --account=vulcan --gres=gpu:4 --pty bash
          </code>
         </td>
         <td>
          <code>
           srun --partition=vulcan-scavenger --qos=vulcan-scavenger --account=vulcan --gres=gpu:4 --pty bash
          </code>
         </td>
        </tr>
       </tbody>
      </table>
      <p>
       Vulcan users (exclusively) can schedule non-interruptible jobs on Vulcan nodes with any non-scavenger job parameters. Please note that the
       <code>
        vulcan-dpart
       </code>
       partition has a
       <code>
        GrpTRES
       </code>
       limit of 100% of the available cores/RAM on all vulcan## in aggregate nodes plus 50% of the available cores/RAM on legacy## nodes in aggregate, so your job may need to wait if all available cores/RAM (or GPUs) are in use. It also has a max submission limit of 500 jobs per user simultaneously so as to not overload the cluster. This is codified by the partition QoS named
       <b>
        vulcan
       </b>
       .
      </p>
      <p>
       Please note that the Vulcan compute nodes are also in the institute-wide
       <code>
        scavenger
       </code>
       partition in Nexus. Vulcan users still have scavenging priority over these nodes via the
       <code>
        vulcan-scavenger
       </code>
       partition (i.e., all
       <code>
        vulcan-
       </code>
       partition jobs (other than
       <code>
        vulcan-scavenger
       </code>
       ) can preempt both
       <code>
        vulcan-scavenger
       </code>
       and
       <code>
        scavenger
       </code>
       partition jobs, and
       <code>
        vulcan-scavenger
       </code>
       partition jobs can preempt
       <code>
        scavenger
       </code>
       partition jobs).
      </p>
      <h2>
       <span class="mw-headline" id="Nodes">
        Nodes
       </span>
      </h2>
      <p>
       There are currently 46
       <a class="mw-redirect" href="/umiacs/index.php/Nexus/Vulcan/GPUs" title="Nexus/Vulcan/GPUs">
        GPU nodes
       </a>
       available running a mixture of NVIDIA RTX A6000, NVIDIA RTX A5000, NVIDIA RTX A4000, NVIDIA Quadro P6000, NVIDIA GeForce GTX 1080 Ti, NVIDIA GeForce RTX 2080 Ti, and NVIDIA Tesla P100 cards. There are also 4 CPU-only nodes available.
      </p>
      <p>
       All nodes are scheduled with the
       <a href="/umiacs/index.php/SLURM" title="SLURM">
        SLURM
       </a>
       resource manager.
      </p>
      <h2>
       <span class="mw-headline" id="Partitions">
        Partitions
       </span>
      </h2>
      <p>
       There are three partitions available to general Vulcan
       <a href="/umiacs/index.php/SLURM" title="SLURM">
        SLURM
       </a>
       users.  You must specify a partition when submitting your job.
      </p>
      <ul>
       <li>
        <b>
         vulcan-dpart
        </b>
        - This is the default partition. Job allocations are guaranteed. Only nodes with GPUs from architectures before NVIDIA's
        <a class="external text" href="https://www.nvidia.com/en-us/data-center/ampere-architecture/" rel="nofollow">
         Ampere architecture
        </a>
        are included in this partition.
       </li>
       <li>
        <b>
         vulcan-scavenger
        </b>
        - This is the alternate partition that allows jobs longer run times and more resources but is preemptable when jobs in other
        <code>
         vulcan-
        </code>
        partitions are ready to be scheduled.
       </li>
       <li>
        <b>
         vulcan-cpu
        </b>
        - This partition is for CPU focused jobs. Job allocations are guaranteed.
       </li>
      </ul>
      <p>
       There are a few additional partitions available to subsets of Vulcan users based on specific requirements.
      </p>
      <ul>
       <li>
        <b>
         vulcan-ampere
        </b>
        - This partition contains nodes with GPUs from NVIDIA's
        <a class="external text" href="https://www.nvidia.com/en-us/data-center/ampere-architecture/" rel="nofollow">
         Ampere architecture
        </a>
        . Job allocations are guaranteed.
        <dl>
         <dd>
          As of Thursday 02/29/2024 at 12pm, there is a 4 hour time limit on interactive jobs in this partition. If you need to run longer jobs, you will need to modify your workflow into a job that can be submitted as a batch script.
         </dd>
         <dd>
          As of Thursday 03/21/2024 at 5pm, there is a limit of 4 CPUs and 48G memory maximum per GPU requested by a job. If you need to run jobs with more CPUs/memory, you will either need to request more GPUs in the job or use a different partition.
         </dd>
        </dl>
       </li>
      </ul>
      <dl>
       <dd>
        Submission is restricted to the Slurm
        <a href="#Accounts">
         accounts
        </a>
        of the faculty who invested in these nodes:
        <ul>
         <li>
          Abhinav Shrivastava (vulcan-abhinav)
         </li>
         <li>
          Jia-Bin Huang (vulcan-jbhuang)
         </li>
         <li>
          Christopher Metzler (vulcan-metzler)
         </li>
         <li>
          Matthias Zwicker (vulcan-zwicker)
         </li>
        </ul>
       </dd>
      </dl>
      <h2>
       <span class="mw-headline" id="Accounts">
        Accounts
       </span>
      </h2>
      <p>
       Vulcan has a base SLURM account
       <code>
        vulcan
       </code>
       which has a modest number of guaranteed billing resources available to all cluster users at any given time.  Other faculty that have invested in Vulcan compute infrastructure have an additional account provided to their sponsored accounts on the cluster.
      </p>
      <p>
       If you do not specify an account when submitting your job, you will receive the
       <b>
        vulcan
       </b>
       account.  If your faculty sponsor has their own account, it is recommended to use that account for job submission.
      </p>
      <p>
       The current faculty accounts are:
      </p>
      <ul>
       <li>
        vulcan-abhinav
       </li>
       <li>
        vulcan-djacobs
       </li>
       <li>
        vulcan-jbhuang
       </li>
       <li>
        vulcan-lsd
       </li>
       <li>
        vulcan-metzler
       </li>
       <li>
        vulcan-rama
       </li>
       <li>
        vulcan-ramani
       </li>
       <li>
        vulcan-yaser
       </li>
       <li>
        vulcan-zwicker
       </li>
      </ul>
      <pre>$ sacctmgr show account format=account%20,description%30,organization%10
             Account                          Descr        Org
-------------------- ------------------------------ ----------
                 ...                            ...        ...
              vulcan                         vulcan     vulcan
      vulcan-abhinav   vulcan - abhinav shrivastava     vulcan
      vulcan-djacobs          vulcan - david jacobs     vulcan
      vulcan-jbhuang         vulcan - jia-bin huang     vulcan
          vulcan-lsd           vulcan - larry davis     vulcan
      vulcan-metzler         vulcan - chris metzler     vulcan
         vulcan-rama        vulcan - rama chellappa     vulcan
       vulcan-ramani     vulcan - ramani duraiswami     vulcan
        vulcan-yaser          vulcan - yaser yacoob     vulcan
      vulcan-zwicker      vulcan - matthias zwicker     vulcan
                 ...                            ...        ...
</pre>
      <p>
       Faculty can manage this list of users via our
       <a class="external text" href="https://intranet.umiacs.umd.edu/directory/secgroup/" rel="nofollow">
        Directory application
       </a>
       in the Security Groups section.  The security group that controls access has the prefix
       <code>
        vulcan_
       </code>
       and then the faculty username.  It will also list
       <code>
        slurm://nexusctl.umiacs.umd.edu
       </code>
       as the associated URI.
      </p>
      <p>
       You can check your account associations by running the
       <b>
        show_assoc
       </b>
       command to see the accounts you are associated with.  Please
       <a href="/umiacs/index.php/HelpDesk" title="HelpDesk">
        contact staff
       </a>
       and include your faculty member in the conversation if you do not see the appropriate association.
      </p>
      <pre>$ show_assoc
      User          Account MaxJobs       GrpTRES                                                                              QOS
---------- ---------------- ------- ------------- --------------------------------------------------------------------------------
       ...              ...     ...                                                                                            ...
   abhinav           vulcan      48                                       vulcan-cpu,vulcan-default,vulcan-medium,vulcan-scavenger
   abhinav   vulcan-abhinav      48                           vulcan-cpu,vulcan-default,vulcan-high,vulcan-medium,vulcan-scavenger
       ...              ...     ...                                                                                            ...
</pre>
      <p>
       You can also see the total number of Track-able Resources (TRES) allowed for each account by running the following command. Please make sure you give the appropriate account that you are looking for. As shown below, there is a concurrent limit of 64 total GPUs for all users not in a contributing faculty group.
      </p>
      <pre>$ sacctmgr show assoc account=vulcan format=user,account,qos,grptres
      User    Account                  QOS       GrpTRES
---------- ---------- -------------------- -------------
               vulcan                        gres/gpu=64
                  ...                                ...
</pre>
      <h2>
       <span class="mw-headline" id="QoS">
        QoS
       </span>
      </h2>
      <p>
       You need to decide the QOS to submit with which will set a certain number of restrictions to your job.  If you do not specify a QoS when submitting your job using the
       <code>
        --qos
       </code>
       parameter, you will receive the
       <b>
        vulcan-default
       </b>
       QoS assuming you are using a Vulcan account.
      </p>
      <p>
       The following
       <code>
        sacctmgr
       </code>
       command will list the current QOS.  Either the
       <code>
        vulcan-default
       </code>
       ,
       <code>
        vulcan-medium
       </code>
       , or
       <code>
        vulcan-high
       </code>
       QOS is required for the vulcan-dpart partition.  Please note that only faculty accounts (see above) have access to the
       <code>
        vulcan-high
       </code>
       QoS.
      </p>
      <p>
       The following example will show you the current limits that the QOS have. The output is truncated to show only relevant Vulcan QoS.
      </p>
      <pre>$ show_qos
                Name     MaxWall                        MaxTRES MaxJobsPU                      MaxTRESPU 
-------------------- ----------- ------------------------------ --------- ------------------------------ 
...
          vulcan-cpu  2-00:00:00                cpu=1024,mem=4T         4                                
      vulcan-default  7-00:00:00       cpu=4,gres/gpu=1,mem=32G         2                                
       vulcan-exempt  7-00:00:00     cpu=32,gres/gpu=8,mem=256G         2                                
         vulcan-high  1-12:00:00     cpu=16,gres/gpu=4,mem=128G         2                                
        vulcan-janus  3-00:00:00    cpu=32,gres/gpu=10,mem=256G                                          
       vulcan-medium  3-00:00:00       cpu=8,gres/gpu=2,mem=64G         2                                
       vulcan-sailon  3-00:00:00     cpu=32,gres/gpu=8,mem=256G                              gres/gpu=48 
    vulcan-scavenger  3-00:00:00     cpu=32,gres/gpu=8,mem=256G                                          
...

$ show_partition_qos
                Name MaxSubmitPU                      MaxTRESPU              GrpTRES 
-------------------- ----------- ------------------------------ -------------------- 
...
              vulcan         500                                 cpu=1760,mem=15824G 
    vulcan-scavenger         500                                                     
...
</pre>
      <h2>
       <span class="mw-headline" id="Storage">
        Storage
       </span>
      </h2>
      <p>
       Vulcan has the following storage available.  Please also review UMIACS
       <a href="/umiacs/index.php/LocalDataStorage" title="LocalDataStorage">
        Local Data Storage
       </a>
       policies including any volume that is labeled as scratch.
      </p>
      <p>
       Vulcan users can also request
       <a href="/umiacs/index.php/Nexus#Project_Allocations" title="Nexus">
        Nexus project allocations
       </a>
       .
      </p>
      <h3>
       <span class="mw-headline" id="Home_Directories">
        Home Directories
       </span>
      </h3>
      <p>
       You have 30GB of home directory storage available at
       <code>
        /nfshomes/&lt;username&gt;
       </code>
       .  It has both
       <a href="/umiacs/index.php/Snapshots" title="Snapshots">
        Snapshots
       </a>
       and
       <a class="mw-redirect" href="/umiacs/index.php/TSM" title="TSM">
        Backups
       </a>
       enabled.
      </p>
      <p>
       Home directories are intended to store personal or configuration files only.  We encourage you to not share any data in your home directory.  You are encouraged to utilize our
       <a href="/umiacs/index.php/GitLab" title="GitLab">
        GitLab
       </a>
       infrastructure to host your code repositories.
      </p>
      <p>
       <b>
        NOTE
       </b>
       : To check your quota on this directory, use the command
       <code>
        df -h ~
       </code>
       .
      </p>
      <h3>
       <span class="mw-headline" id="Scratch_Directories">
        Scratch Directories
       </span>
      </h3>
      <p>
       Scratch data has no data protection including no snapshots and the data is not backed up. There are two types of scratch directories in the Vulcan compute infrastructure:
      </p>
      <ul>
       <li>
        Network scratch directory
       </li>
       <li>
        Local scratch directories
       </li>
      </ul>
      <h4>
       <span class="mw-headline" id="Network_Scratch_Directory">
        Network Scratch Directory
       </span>
      </h4>
      <p>
       You have 300GB of scratch storage available at
       <code>
        /vulcanscratch/&lt;username&gt;
       </code>
       .
       <b>
        It is not backed up or protected in any way.
       </b>
       This directory is
       <b>
        automounted
       </b>
       so you will need to
       <code>
        cd
       </code>
       into the directory or request/specify a fully qualified file path to access this.
      </p>
      <p>
       You may request a temporary increase of up to 500GB total space for a maximum of 120 days without any faculty approval by
       <a href="/umiacs/index.php/HelpDesk" title="HelpDesk">
        contacting staff
       </a>
       .  Once the temporary increase period is over, you will be contacted and given a one-week window of opportunity to clean and secure your data before staff will forcibly remove data to get your space back under 300GB.  If you need space beyond 500GB or for longer than 120 days, you will need faculty approval and/or a project directory.
      </p>
      <p>
       This file system is available on all submission, data management, and computational nodes within the cluster.
      </p>
      <h4>
       <span class="mw-headline" id="Local_Scratch_Directories">
        Local Scratch Directories
       </span>
      </h4>
      <p>
       Each computational node that you can schedule compute jobs on has one or more local scratch directories.  These are always named
       <code>
        /scratch0
       </code>
       ,
       <code>
        /scratch1
       </code>
       , etc.  These are almost always more performant than any other storage available to the job.  However, you must stage their data within the confine of their job and stage the data out before the end of their job.
      </p>
      <p>
       These local scratch directories have a tmpwatch job which will
       <b>
        delete unaccessed data after 90 days
       </b>
       , scheduled via maintenance jobs to run once a month at 1am.  Different nodes will run the maintenance jobs on different days of the month to ensure the cluster is still highly available at all times.  Please make sure you secure any data you write to these directories at the end of your job.
      </p>
      <h3>
       <span class="mw-headline" id="Datasets">
        Datasets
       </span>
      </h3>
      <p>
       We have read-only dataset storage available at
       <code>
        /fs/vulcan-datasets
       </code>
       .  If there are datasets that you would like to see curated and available, please see
       <a href="/umiacs/index.php/Datasets" title="Datasets">
        this page
       </a>
       .
      </p>
      <p>
       The list of Vulcan datasets we currently host can be viewed
       <a class="external text" href="https://info.umiacs.umd.edu/datasets/list/?q=Vulcan" rel="nofollow">
        here
       </a>
       .
      </p>
      <h3>
       <span class="mw-headline" id="Project_Storage">
        Project Storage
       </span>
      </h3>
      <p>
       Users within the Vulcan compute infrastructure can request project based allocations for up to 10TB for up to 180 days by
       <a href="/umiacs/index.php/HelpDesk" title="HelpDesk">
        contacting staff
       </a>
       with approval from the Vulcan faculty manager (Dr. Shrivastava).  These allocations will be available from
       <code>
        /fs/vulcan-projects
       </code>
       and
       <code>
        /fs/cfar-projects
       </code>
       under a name that you provide when you request the allocation.  Near the end of the allocation period, staff will contact you and ask if you would like to renew the allocation for up to another 180 days (requires re-approval from Dr. Shrivastava).
      </p>
      <ul>
       <li>
        If you are no longer in need of the storage allocation, you will need to relocate all desired data within two weeks of the end of the allocation period.  Staff will then remove the allocation.
       </li>
       <li>
        If you do not respond to staff's request by the end of the allocation period, staff will make the allocation temporarily inaccessible.
        <ul>
         <li>
          If you do respond asking for renewal but the original faculty approver does not respond within two weeks of the end of the allocation period, staff will also make the allocation temporarily inaccessible.
         </li>
         <li>
          If one month from the end of the allocation period is reached without both you and the faculty approver responding, staff will remove the allocation.
         </li>
        </ul>
       </li>
      </ul>
      <p>
       Project storage is fully protected.  It has
       <a href="/umiacs/index.php/Snapshots" title="Snapshots">
        snapshots
       </a>
       enabled and is
       <a href="/umiacs/index.php/NightlyBackups" title="NightlyBackups">
        backed up nightly
       </a>
       .
      </p>
      <h3>
       <span class="mw-headline" id="Object_Storage">
        Object Storage
       </span>
      </h3>
      <p>
       All Vulcan users can request project allocations in the
       <a class="external text" href="https://obj.umiacs.umd.edu/obj/help" rel="nofollow">
        UMIACS Object Store
       </a>
       . Please
       <a href="/umiacs/index.php/HelpDesk" title="HelpDesk">
        contact staff
       </a>
       with a short project name and the amount of storage you will need to get started.
      </p>
      <p>
       To access this storage, you'll need to use a
       <a href="/umiacs/index.php/S3Clients" title="S3Clients">
        S3 client
       </a>
       or our
       <a href="/umiacs/index.php/UMobj" title="UMobj">
        UMobj
       </a>
       command line utilities.
      </p>
      <p>
       An example on how to use the umobj command line utilities can be found
       <a href="/umiacs/index.php/UMobj/Example" title="UMobj/Example">
        here
       </a>
       .  A full set of documentation for the utilities can be found on the
       <a class="external text" href="https://gitlab.umiacs.umd.edu/staff/umobj/blob/master/README.md#umobj" rel="nofollow">
        umobj Gitlab page
       </a>
       .
      </p>
      <h2>
       <span class="mw-headline" id="Migration">
        Migration
       </span>
      </h2>
      <h3>
       <span class="mw-headline" id="Home_Directories_2">
        Home Directories
       </span>
      </h3>
      <p>
       The
       <a href="/umiacs/index.php/Nexus" title="Nexus">
        Nexus
       </a>
       uses
       <a href="/umiacs/index.php/NFShomes" title="NFShomes">
        NFShomes
       </a>
       home directories - if your UMIACS account was created before February 22nd, 2023, you were using
       <code>
        /cfarhomes/&lt;username&gt;
       </code>
       as your home directory on the standalone Vulcan cluster. While
       <code>
        /cfarhomes
       </code>
       is available on Nexus, your shell initialization scripts from it will not automatically load. Please copy over anything you need to your
       <code>
        /nfshomes/&lt;username&gt;
       </code>
       directory at your earliest convenience, as
       <code>
        /cfarhomes
       </code>
       will be retired in a two phase process:
      </p>
      <ul>
       <li>
        Fri 11/17/2023, 5pm: cfarhomes directories are made read-only
       </li>
       <li>
        Thu 12/21/2023, 5-8pm (
        <a href="/umiacs/index.php/MonthlyMaintenanceWindow" title="MonthlyMaintenanceWindow">
         monthly maintenance window
        </a>
        ): cfarhomes directories are taken offline
       </li>
      </ul>
     </div>
     <div class="printfooter" data-nosnippet="">
      Retrieved from "
      <a dir="ltr" href="https://wiki.umiacs.umd.edu/umiacs/index.php?title=Nexus/Vulcan&amp;oldid=12037">
       https://wiki.umiacs.umd.edu/umiacs/index.php?title=Nexus/Vulcan&amp;oldid=12037
      </a>
      "
     </div>
    </div>
    <div class="catlinks catlinks-allhidden" data-mw="interface" id="catlinks">
    </div>
   </div>
  </div>
  <div id="mw-navigation">
   <h2>
    Navigation menu
   </h2>
   <div id="mw-head">
    <nav aria-labelledby="p-personal-label" class="vector-menu mw-portlet mw-portlet-personal vector-user-menu-legacy" id="p-personal" role="navigation">
     <h3 class="vector-menu-heading" id="p-personal-label">
      <span class="vector-menu-heading-label">
       Personal tools
      </span>
     </h3>
     <div class="vector-menu-content">
      <ul class="vector-menu-content-list">
       <li class="mw-list-item" id="pt-login">
        <a accesskey="o" href="/umiacs/index.php?title=Special:UserLogin&amp;returnto=Nexus%2FVulcan" title="You are encouraged to log in; however, it is not mandatory [o]">
         <span>
          Log in
         </span>
        </a>
       </li>
      </ul>
     </div>
    </nav>
    <div id="left-navigation">
     <nav aria-labelledby="p-namespaces-label" class="vector-menu mw-portlet mw-portlet-namespaces vector-menu-tabs vector-menu-tabs-legacy" id="p-namespaces" role="navigation">
      <h3 class="vector-menu-heading" id="p-namespaces-label">
       <span class="vector-menu-heading-label">
        Namespaces
       </span>
      </h3>
      <div class="vector-menu-content">
       <ul class="vector-menu-content-list">
        <li class="selected mw-list-item" id="ca-nstab-main">
         <a accesskey="c" href="/umiacs/index.php/Nexus/Vulcan" title="View the content page [c]">
          <span>
           Page
          </span>
         </a>
        </li>
        <li class="new mw-list-item" id="ca-talk">
         <a accesskey="t" href="/umiacs/index.php?title=Talk:Nexus/Vulcan&amp;action=edit&amp;redlink=1" rel="discussion" title="Discussion about the content page (page does not exist) [t]">
          <span>
           Discussion
          </span>
         </a>
        </li>
       </ul>
      </div>
     </nav>
     <nav aria-labelledby="p-variants-label" class="vector-menu mw-portlet mw-portlet-variants emptyPortlet vector-menu-dropdown" id="p-variants" role="navigation">
      <input aria-haspopup="true" aria-labelledby="p-variants-label" class="vector-menu-checkbox" data-event-name="ui.dropdown-p-variants" id="p-variants-checkbox" role="button" type="checkbox"/>
      <label aria-label="Change language variant" class="vector-menu-heading" id="p-variants-label">
       <span class="vector-menu-heading-label">
        English
       </span>
      </label>
      <div class="vector-menu-content">
       <ul class="vector-menu-content-list">
       </ul>
      </div>
     </nav>
    </div>
    <div id="right-navigation">
     <nav aria-labelledby="p-views-label" class="vector-menu mw-portlet mw-portlet-views vector-menu-tabs vector-menu-tabs-legacy" id="p-views" role="navigation">
      <h3 class="vector-menu-heading" id="p-views-label">
       <span class="vector-menu-heading-label">
        Views
       </span>
      </h3>
      <div class="vector-menu-content">
       <ul class="vector-menu-content-list">
        <li class="selected mw-list-item" id="ca-view">
         <a href="/umiacs/index.php/Nexus/Vulcan">
          <span>
           Read
          </span>
         </a>
        </li>
        <li class="mw-list-item" id="ca-viewsource">
         <a accesskey="e" href="/umiacs/index.php?title=Nexus/Vulcan&amp;action=edit" title="This page is protected.
You can view its source [e]">
          <span>
           View source
          </span>
         </a>
        </li>
        <li class="mw-list-item" id="ca-history">
         <a accesskey="h" href="/umiacs/index.php?title=Nexus/Vulcan&amp;action=history" title="Past revisions of this page [h]">
          <span>
           View history
          </span>
         </a>
        </li>
       </ul>
      </div>
     </nav>
     <nav aria-labelledby="p-cactions-label" class="vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-menu-dropdown" id="p-cactions" role="navigation" title="More options">
      <input aria-haspopup="true" aria-labelledby="p-cactions-label" class="vector-menu-checkbox" data-event-name="ui.dropdown-p-cactions" id="p-cactions-checkbox" role="button" type="checkbox"/>
      <label class="vector-menu-heading" id="p-cactions-label">
       <span class="vector-menu-heading-label">
        More
       </span>
      </label>
      <div class="vector-menu-content">
       <ul class="vector-menu-content-list">
       </ul>
      </div>
     </nav>
     <div class="vector-search-box-vue vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box" id="p-search" role="search">
      <div>
       <h3>
        <label for="searchInput">
         Search
        </label>
       </h3>
       <form action="/umiacs/index.php" class="vector-search-box-form" id="searchform">
        <div class="vector-search-box-inner" data-search-loc="header-navigation" id="simpleSearch">
         <input accesskey="f" aria-label="Search UMIACS" autocapitalize="sentences" class="vector-search-box-input" id="searchInput" name="search" placeholder="Search UMIACS" title="Search UMIACS [f]" type="search"/>
         <input name="title" type="hidden" value="Special:Search"/>
         <input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search the pages for this text" type="submit" value="Search"/>
         <input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/>
        </div>
       </form>
      </div>
     </div>
    </div>
   </div>
   <div id="mw-panel">
    <div id="p-logo" role="banner">
     <a class="mw-wiki-logo" href="/umiacs/index.php/Main_Page" title="Visit the main page">
     </a>
    </div>
    <nav aria-labelledby="p-navigation-label" class="vector-menu mw-portlet mw-portlet-navigation vector-menu-portal portal" id="p-navigation" role="navigation">
     <h3 class="vector-menu-heading" id="p-navigation-label">
      <span class="vector-menu-heading-label">
       Navigation
      </span>
     </h3>
     <div class="vector-menu-content">
      <ul class="vector-menu-content-list">
       <li class="mw-list-item" id="n-mainpage">
        <a accesskey="z" href="/umiacs/index.php/Main_Page" title="Visit the main page [z]">
         <span>
          Main Page
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="n-Getting-Started">
        <a href="/umiacs/index.php/GettingStarted">
         <span>
          Getting Started
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="n-Core-Services">
        <a href="/umiacs/index.php/CoreServices">
         <span>
          Core Services
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="n-Lab-Facilities">
        <a href="/umiacs/index.php/LabFacilities">
         <span>
          Lab Facilities
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="n-Placing-Orders">
        <a href="/umiacs/index.php/Orders">
         <span>
          Placing Orders
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="n-Support">
        <a href="/umiacs/index.php/HelpDesk">
         <span>
          Support
         </span>
        </a>
       </li>
      </ul>
     </div>
    </nav>
    <nav aria-labelledby="p-tb-label" class="vector-menu mw-portlet mw-portlet-tb vector-menu-portal portal" id="p-tb" role="navigation">
     <h3 class="vector-menu-heading" id="p-tb-label">
      <span class="vector-menu-heading-label">
       Tools
      </span>
     </h3>
     <div class="vector-menu-content">
      <ul class="vector-menu-content-list">
       <li class="mw-list-item" id="t-whatlinkshere">
        <a accesskey="j" href="/umiacs/index.php/Special:WhatLinksHere/Nexus/Vulcan" title="A list of all wiki pages that link here [j]">
         <span>
          What links here
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="t-recentchangeslinked">
        <a accesskey="k" href="/umiacs/index.php/Special:RecentChangesLinked/Nexus/Vulcan" rel="nofollow" title="Recent changes in pages linked from this page [k]">
         <span>
          Related changes
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="t-specialpages">
        <a accesskey="q" href="/umiacs/index.php/Special:SpecialPages" title="A list of all special pages [q]">
         <span>
          Special pages
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="t-print">
        <a accesskey="p" href="javascript:print();" rel="alternate" title="Printable version of this page [p]">
         <span>
          Printable version
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="t-permalink">
        <a href="/umiacs/index.php?title=Nexus/Vulcan&amp;oldid=12037" title="Permanent link to this revision of this page">
         <span>
          Permanent link
         </span>
        </a>
       </li>
       <li class="mw-list-item" id="t-info">
        <a href="/umiacs/index.php?title=Nexus/Vulcan&amp;action=info" title="More information about this page">
         <span>
          Page information
         </span>
        </a>
       </li>
      </ul>
     </div>
    </nav>
   </div>
  </div>
  <footer class="mw-footer" id="footer" role="contentinfo">
   <ul id="footer-info">
    <li id="footer-info-lastmod">
     This page was last edited on 17 September 2024, at 16:37.
    </li>
   </ul>
   <ul id="footer-places">
    <li id="footer-places-privacy">
     <a href="/umiacs/index.php/UMIACS:Privacy_policy">
      Privacy policy
     </a>
    </li>
    <li id="footer-places-about">
     <a href="/umiacs/index.php/UMIACS:About">
      About UMIACS
     </a>
    </li>
    <li id="footer-places-disclaimer">
     <a href="/umiacs/index.php/UMIACS:General_disclaimer">
      Disclaimers
     </a>
    </li>
   </ul>
   <ul class="noprint" id="footer-icons">
    <li id="footer-poweredbyico">
     <a href="https://www.mediawiki.org/">
      <img alt="Powered by MediaWiki" height="31" loading="lazy" src="/umiacs/resources/assets/poweredby_mediawiki_88x31.png" srcset="/umiacs/resources/assets/poweredby_mediawiki_132x47.png 1.5x, /umiacs/resources/assets/poweredby_mediawiki_176x62.png 2x" width="88"/>
     </a>
    </li>
   </ul>
  </footer>
  <script>
   (RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.022","walltime":"0.025","ppvisitednodes":{"value":90,"limit":1000000},"postexpandincludesize":{"value":470,"limit":2097152},"templateargumentsize":{"value":0,"limit":2097152},"expansiondepth":{"value":2,"limit":100},"expensivefunctioncount":{"value":0,"limit":100},"unstrip-depth":{"value":0,"limit":20},"unstrip-size":{"value":3552,"limit":5000000},"timingprofile":["100.00%    3.526      1 Template:Nfshomes","100.00%    3.526      1 -total"]},"cachereport":{"timestamp":"20241002164949","ttl":86400,"transientcontent":false}}});mw.config.set({"wgBackendResponseTime":158});});
  </script>
 </body>
</html>
